# Project Title: Hybrid VLM for Zero-Shot Image Captioning Refinement

Status: Under Development / Research Project<br><br>

This repository contains the implementation and evaluation scripts for comparing two distinct approaches to image captioning: the ZeroCap Zero-Shot Baseline and a Fine-Tuned Hybrid Vision-Language Model (VLM) using Self-Critical Sequence Training (SCST). The project demonstrates how leveraging modern LLMs and targeted fine-tuning overcomes the primary limitations (fluency, speed) of older guidance-based zero-shot methods.
